{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heartbeat Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "The data is cleaned up. There are no unqueal length sequences. And, there is no zero padding. So, there is no need to use any `Masking` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"Target\" value in the data set:\n",
    "\n",
    "heartbeat = pd.read_csv(\"heartbeat_cleaned.csv\")\n",
    "heartbeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 81)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartbeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heartbeat['Target']\n",
    "x = heartbeat.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.961 , 0.783 , 0.549 , ..., 0.132 , 0.18  , 0.442 ],\n",
       "       [1.    , 0.938 , 0.751 , ..., 0.143 , 0.14  , 0.15  ],\n",
       "       [0.889 , 0.489 , 0.278 , ..., 0.15  , 0.05  , 0.0778],\n",
       "       ...,\n",
       "       [0.958 , 0.942 , 0.34  , ..., 0.175 , 0.229 , 0.331 ],\n",
       "       [1.    , 0.897 , 0.323 , ..., 0.222 , 0.239 , 0.249 ],\n",
       "       [0.939 , 0.843 , 0.254 , ..., 0.307 , 0.304 , 0.282 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (5572,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.961 ],\n",
       "        [0.783 ],\n",
       "        [0.549 ],\n",
       "        ...,\n",
       "        [0.132 ],\n",
       "        [0.18  ],\n",
       "        [0.442 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.938 ],\n",
       "        [0.751 ],\n",
       "        ...,\n",
       "        [0.143 ],\n",
       "        [0.14  ],\n",
       "        [0.15  ]],\n",
       "\n",
       "       [[0.889 ],\n",
       "        [0.489 ],\n",
       "        [0.278 ],\n",
       "        ...,\n",
       "        [0.15  ],\n",
       "        [0.05  ],\n",
       "        [0.0778]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.958 ],\n",
       "        [0.942 ],\n",
       "        [0.34  ],\n",
       "        ...,\n",
       "        [0.175 ],\n",
       "        [0.229 ],\n",
       "        [0.331 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.897 ],\n",
       "        [0.323 ],\n",
       "        ...,\n",
       "        [0.222 ],\n",
       "        [0.239 ],\n",
       "        [0.249 ]],\n",
       "\n",
       "       [[0.939 ],\n",
       "        [0.843 ],\n",
       "        [0.254 ],\n",
       "        ...,\n",
       "        [0.307 ],\n",
       "        [0.304 ],\n",
       "        [0.282 ]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 4, 0, 4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.582035\n",
       "4    0.198995\n",
       "2    0.155402\n",
       "1    0.055905\n",
       "3    0.007663\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartbeat['Target'].value_counts()/len(heartbeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional shallow model using Keras (with only one hidden layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(40, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.7170 - accuracy: 0.7629 - val_loss: 0.5235 - val_accuracy: 0.8275\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.8444 - val_loss: 0.6891 - val_accuracy: 0.6993\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8711 - val_loss: 0.5329 - val_accuracy: 0.7956\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8898 - val_loss: 0.4029 - val_accuracy: 0.8652\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.9031 - val_loss: 0.3082 - val_accuracy: 0.9112\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.9067 - val_loss: 0.5399 - val_accuracy: 0.8664\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.9112 - val_loss: 0.3721 - val_accuracy: 0.8807\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.9131 - val_loss: 0.3021 - val_accuracy: 0.9158\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2721 - accuracy: 0.9173 - val_loss: 0.3007 - val_accuracy: 0.9100\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.9214 - val_loss: 0.2899 - val_accuracy: 0.9146\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.9264 - val_loss: 0.3369 - val_accuracy: 0.8970\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.9253 - val_loss: 0.2756 - val_accuracy: 0.9238\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9284 - val_loss: 0.2553 - val_accuracy: 0.9288\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 0s 998us/step - loss: 0.2339 - accuracy: 0.9293 - val_loss: 0.3706 - val_accuracy: 0.8982\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.9307 - val_loss: 0.2568 - val_accuracy: 0.9288\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9314 - val_loss: 0.6745 - val_accuracy: 0.6616\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9336 - val_loss: 0.2913 - val_accuracy: 0.9192\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9311 - val_loss: 0.2664 - val_accuracy: 0.9292\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=100,\n",
    "                    validation_data=(test_x, test_y),callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26640573143959045, 0.9292294979095459]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.27\n",
      "accuracy: 92.92%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional deep model using Keras (with two or more hidden layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIPE Architecture\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=80))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 405       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,845\n",
      "Trainable params: 19,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.2297 - accuracy: 0.4928 - val_loss: 0.9177 - val_accuracy: 0.6696\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8180 - accuracy: 0.7452 - val_loss: 0.6827 - val_accuracy: 0.8074\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6524 - accuracy: 0.7933 - val_loss: 0.6201 - val_accuracy: 0.7961\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5716 - accuracy: 0.8123 - val_loss: 0.5090 - val_accuracy: 0.8484\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5038 - accuracy: 0.8369 - val_loss: 0.4576 - val_accuracy: 0.8576\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.8580 - val_loss: 0.4181 - val_accuracy: 0.8647\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8724 - val_loss: 0.3855 - val_accuracy: 0.8840\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8850 - val_loss: 0.3713 - val_accuracy: 0.8869\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8873 - val_loss: 0.3517 - val_accuracy: 0.8999\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.8999 - val_loss: 0.3369 - val_accuracy: 0.8987\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3233 - accuracy: 0.9054 - val_loss: 0.3494 - val_accuracy: 0.8924\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3256 - accuracy: 0.9006 - val_loss: 0.4021 - val_accuracy: 0.8735\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3218 - accuracy: 0.9018 - val_loss: 0.3293 - val_accuracy: 0.8982\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2936 - accuracy: 0.9142 - val_loss: 0.3139 - val_accuracy: 0.8999\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2742 - accuracy: 0.9174 - val_loss: 0.2842 - val_accuracy: 0.9167\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2626 - accuracy: 0.9198 - val_loss: 0.2989 - val_accuracy: 0.9087\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2616 - accuracy: 0.9214 - val_loss: 0.2927 - val_accuracy: 0.9125\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2678 - accuracy: 0.9162 - val_loss: 0.2739 - val_accuracy: 0.9192\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2422 - accuracy: 0.9252 - val_loss: 0.2667 - val_accuracy: 0.9263\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2353 - accuracy: 0.9270 - val_loss: 0.2580 - val_accuracy: 0.9238\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2322 - accuracy: 0.9305 - val_loss: 0.2535 - val_accuracy: 0.9246\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2272 - accuracy: 0.9271 - val_loss: 0.2605 - val_accuracy: 0.9238\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2242 - accuracy: 0.9271 - val_loss: 0.2602 - val_accuracy: 0.9217\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2182 - accuracy: 0.9320 - val_loss: 0.2515 - val_accuracy: 0.9284\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2114 - accuracy: 0.9304 - val_loss: 0.2643 - val_accuracy: 0.9196\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.9280 - val_loss: 0.2873 - val_accuracy: 0.9242\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2259 - accuracy: 0.9311 - val_loss: 0.3036 - val_accuracy: 0.9003\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2340 - accuracy: 0.9234 - val_loss: 0.2549 - val_accuracy: 0.9259\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2054 - accuracy: 0.9325 - val_loss: 0.2439 - val_accuracy: 0.9305\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1999 - accuracy: 0.9363 - val_loss: 0.2409 - val_accuracy: 0.9376\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1876 - accuracy: 0.9417 - val_loss: 0.2412 - val_accuracy: 0.9326\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1984 - accuracy: 0.9397 - val_loss: 0.2437 - val_accuracy: 0.9330\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1984 - accuracy: 0.9363 - val_loss: 0.2457 - val_accuracy: 0.9343\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1895 - accuracy: 0.9417 - val_loss: 0.2244 - val_accuracy: 0.9389\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1744 - accuracy: 0.9449 - val_loss: 0.2179 - val_accuracy: 0.9372\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1711 - accuracy: 0.9456 - val_loss: 0.2187 - val_accuracy: 0.9372\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.9472 - val_loss: 0.2187 - val_accuracy: 0.9343\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1574 - accuracy: 0.9532 - val_loss: 0.2165 - val_accuracy: 0.9405\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.9514 - val_loss: 0.2088 - val_accuracy: 0.9430\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 0.9541 - val_loss: 0.2210 - val_accuracy: 0.9447\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9478 - val_loss: 0.2359 - val_accuracy: 0.9380\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1574 - accuracy: 0.9514 - val_loss: 0.2149 - val_accuracy: 0.9430\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1502 - accuracy: 0.9532 - val_loss: 0.2114 - val_accuracy: 0.9397\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1434 - accuracy: 0.9537 - val_loss: 0.2383 - val_accuracy: 0.9368\n",
      "Epoch 44: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=100, batch_size=1000,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23832276463508606, 0.9367671608924866]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.24\n",
      "accuracy: 93.68%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow LSTM Model (with only one LSTM layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(5, activation='softmax' , input_shape=[n_steps, n_inputs])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/175 [==============================] - 4s 16ms/step - loss: 1.1619 - accuracy: 0.5720 - val_loss: 1.0708 - val_accuracy: 0.5930\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 1.0567 - accuracy: 0.5817 - val_loss: 1.0695 - val_accuracy: 0.5733\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 1.0507 - accuracy: 0.5772 - val_loss: 1.0566 - val_accuracy: 0.6089\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 1.0441 - accuracy: 0.5813 - val_loss: 1.0698 - val_accuracy: 0.6005\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 1.0412 - accuracy: 0.5881 - val_loss: 1.0499 - val_accuracy: 0.5787\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0377 - accuracy: 0.5800 - val_loss: 1.0589 - val_accuracy: 0.6009\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 1.0349 - accuracy: 0.5808 - val_loss: 1.0517 - val_accuracy: 0.5913\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0331 - accuracy: 0.5829 - val_loss: 1.0419 - val_accuracy: 0.5758\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0297 - accuracy: 0.5858 - val_loss: 1.0587 - val_accuracy: 0.5750\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0275 - accuracy: 0.5910 - val_loss: 1.0453 - val_accuracy: 0.5829\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 1.0249 - accuracy: 0.6014 - val_loss: 1.0322 - val_accuracy: 0.6193\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 1.0202 - accuracy: 0.6086 - val_loss: 1.0296 - val_accuracy: 0.6248\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0180 - accuracy: 0.6136 - val_loss: 1.0301 - val_accuracy: 0.6269\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0264 - accuracy: 0.5998 - val_loss: 1.0315 - val_accuracy: 0.5854\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0164 - accuracy: 0.6012 - val_loss: 1.0227 - val_accuracy: 0.6290\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0093 - accuracy: 0.6168 - val_loss: 1.0240 - val_accuracy: 0.6294\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 1.0037 - accuracy: 0.6211 - val_loss: 1.0072 - val_accuracy: 0.6302\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 0.9988 - accuracy: 0.6233 - val_loss: 1.0048 - val_accuracy: 0.6407\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.9920 - accuracy: 0.6258 - val_loss: 0.9934 - val_accuracy: 0.6428\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 0.9812 - accuracy: 0.6314 - val_loss: 0.9813 - val_accuracy: 0.6474\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.9618 - accuracy: 0.6310 - val_loss: 0.9547 - val_accuracy: 0.6432\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.9431 - accuracy: 0.6380 - val_loss: 0.9197 - val_accuracy: 0.6583\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.9136 - accuracy: 0.6664 - val_loss: 0.9190 - val_accuracy: 0.6704\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.8941 - accuracy: 0.6868 - val_loss: 0.8612 - val_accuracy: 0.7111\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.8731 - accuracy: 0.6936 - val_loss: 0.9465 - val_accuracy: 0.6562\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.8694 - accuracy: 0.6942 - val_loss: 0.9160 - val_accuracy: 0.6662\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.8563 - accuracy: 0.6965 - val_loss: 0.8190 - val_accuracy: 0.7286\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.8439 - accuracy: 0.7132 - val_loss: 0.9828 - val_accuracy: 0.6353\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.8340 - accuracy: 0.7136 - val_loss: 0.8667 - val_accuracy: 0.6922\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.8283 - accuracy: 0.7143 - val_loss: 0.8312 - val_accuracy: 0.7136\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.8198 - accuracy: 0.7200 - val_loss: 0.9181 - val_accuracy: 0.6692\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.8157 - accuracy: 0.7213 - val_loss: 0.8094 - val_accuracy: 0.7211\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.8026 - accuracy: 0.7231 - val_loss: 0.7874 - val_accuracy: 0.7337\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7961 - accuracy: 0.7283 - val_loss: 0.8066 - val_accuracy: 0.7127\n",
      "Epoch 35/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7859 - accuracy: 0.7337 - val_loss: 0.7712 - val_accuracy: 0.7349\n",
      "Epoch 36/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7716 - accuracy: 0.7437 - val_loss: 0.7766 - val_accuracy: 0.7374\n",
      "Epoch 37/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.7641 - accuracy: 0.7511 - val_loss: 0.7518 - val_accuracy: 0.7387\n",
      "Epoch 38/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7532 - accuracy: 0.7525 - val_loss: 0.7707 - val_accuracy: 0.7274\n",
      "Epoch 39/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7475 - accuracy: 0.7522 - val_loss: 0.7353 - val_accuracy: 0.7479\n",
      "Epoch 40/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7330 - accuracy: 0.7588 - val_loss: 0.7221 - val_accuracy: 0.7559\n",
      "Epoch 41/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7341 - accuracy: 0.7588 - val_loss: 0.7109 - val_accuracy: 0.7676\n",
      "Epoch 42/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7219 - accuracy: 0.7678 - val_loss: 0.7127 - val_accuracy: 0.7705\n",
      "Epoch 43/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.7098 - accuracy: 0.7719 - val_loss: 0.6829 - val_accuracy: 0.7806\n",
      "Epoch 44/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.6974 - accuracy: 0.7800 - val_loss: 0.7080 - val_accuracy: 0.7559\n",
      "Epoch 45/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.6882 - accuracy: 0.7868 - val_loss: 0.7078 - val_accuracy: 0.7542\n",
      "Epoch 46/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.6754 - accuracy: 0.7950 - val_loss: 0.6755 - val_accuracy: 0.7797\n",
      "Epoch 47/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.6685 - accuracy: 0.7956 - val_loss: 0.6760 - val_accuracy: 0.7927\n",
      "Epoch 48/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.6589 - accuracy: 0.8024 - val_loss: 0.9616 - val_accuracy: 0.6495\n",
      "Epoch 49/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.6659 - accuracy: 0.7941 - val_loss: 0.6273 - val_accuracy: 0.8153\n",
      "Epoch 50/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.6437 - accuracy: 0.8064 - val_loss: 0.6921 - val_accuracy: 0.7751\n",
      "Epoch 51/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.6408 - accuracy: 0.8026 - val_loss: 0.6865 - val_accuracy: 0.7760\n",
      "Epoch 52/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.6398 - accuracy: 0.8038 - val_loss: 0.6434 - val_accuracy: 0.8015\n",
      "Epoch 53/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.6343 - accuracy: 0.8089 - val_loss: 0.6443 - val_accuracy: 0.7923\n",
      "Epoch 54/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.6337 - accuracy: 0.8060 - val_loss: 0.7015 - val_accuracy: 0.7764\n",
      "Epoch 54: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=100,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7014719247817993, 0.7763819098472595]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.70\n",
      "accuracy: 77.64%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep LSTM Model (with only two LSTM layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(9, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(9, return_sequences=False),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/175 [==============================] - 8s 31ms/step - loss: 1.1408 - accuracy: 0.5806 - val_loss: 1.1270 - val_accuracy: 0.5854\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 1.1017 - accuracy: 0.5879 - val_loss: 1.0943 - val_accuracy: 0.5854\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 1.0654 - accuracy: 0.5885 - val_loss: 1.0466 - val_accuracy: 0.6227\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 1.0477 - accuracy: 0.6168 - val_loss: 1.0478 - val_accuracy: 0.6298\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 1.0391 - accuracy: 0.6023 - val_loss: 1.0957 - val_accuracy: 0.6160\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 1.0257 - accuracy: 0.6131 - val_loss: 0.9610 - val_accuracy: 0.6621\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.8167 - accuracy: 0.7062 - val_loss: 0.7062 - val_accuracy: 0.7697\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.6726 - accuracy: 0.7778 - val_loss: 0.6743 - val_accuracy: 0.8015\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.6158 - accuracy: 0.8037 - val_loss: 0.5806 - val_accuracy: 0.8224\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.5982 - accuracy: 0.8092 - val_loss: 0.5118 - val_accuracy: 0.8543\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.4923 - accuracy: 0.8525 - val_loss: 0.6900 - val_accuracy: 0.7621\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.4905 - accuracy: 0.8528 - val_loss: 1.1976 - val_accuracy: 0.6608\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.6077 - accuracy: 0.7992 - val_loss: 0.4372 - val_accuracy: 0.8848\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.4231 - accuracy: 0.8805 - val_loss: 0.4096 - val_accuracy: 0.8907\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 6s 32ms/step - loss: 0.4011 - accuracy: 0.8912 - val_loss: 0.4774 - val_accuracy: 0.8622\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.4139 - accuracy: 0.8816 - val_loss: 0.4395 - val_accuracy: 0.8760\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 0.3849 - accuracy: 0.8977 - val_loss: 0.3450 - val_accuracy: 0.9112\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 6s 32ms/step - loss: 0.3701 - accuracy: 0.8979 - val_loss: 0.3833 - val_accuracy: 0.8928\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.3519 - accuracy: 0.9031 - val_loss: 0.3341 - val_accuracy: 0.9112\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 6s 32ms/step - loss: 0.3629 - accuracy: 0.8986 - val_loss: 0.3276 - val_accuracy: 0.9116\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 0.3493 - accuracy: 0.9020 - val_loss: 0.3620 - val_accuracy: 0.8920\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 0.3471 - accuracy: 0.9038 - val_loss: 0.3254 - val_accuracy: 0.9125\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 0.3242 - accuracy: 0.9076 - val_loss: 0.3234 - val_accuracy: 0.9091\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 6s 32ms/step - loss: 0.3365 - accuracy: 0.9029 - val_loss: 0.3279 - val_accuracy: 0.9066\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 0.3176 - accuracy: 0.9101 - val_loss: 0.3384 - val_accuracy: 0.9037\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.3331 - accuracy: 0.9058 - val_loss: 0.3368 - val_accuracy: 0.9054\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.3194 - accuracy: 0.9092 - val_loss: 0.3030 - val_accuracy: 0.9158\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 0.3333 - accuracy: 0.9038 - val_loss: 0.3399 - val_accuracy: 0.8970\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.3689 - accuracy: 0.8907 - val_loss: 0.4167 - val_accuracy: 0.8740\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.3369 - accuracy: 0.9018 - val_loss: 0.3097 - val_accuracy: 0.9112\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.3067 - accuracy: 0.9106 - val_loss: 0.3002 - val_accuracy: 0.9150\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 6s 37ms/step - loss: 0.3003 - accuracy: 0.9139 - val_loss: 0.3056 - val_accuracy: 0.9129\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.2941 - accuracy: 0.9164 - val_loss: 0.2931 - val_accuracy: 0.9196\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.2923 - accuracy: 0.9183 - val_loss: 0.3062 - val_accuracy: 0.9162\n",
      "Epoch 35/100\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.2864 - accuracy: 0.9183 - val_loss: 0.2833 - val_accuracy: 0.9175\n",
      "Epoch 36/100\n",
      "175/175 [==============================] - 7s 37ms/step - loss: 0.2823 - accuracy: 0.9203 - val_loss: 0.2835 - val_accuracy: 0.9162\n",
      "Epoch 37/100\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 0.2855 - accuracy: 0.9178 - val_loss: 0.2959 - val_accuracy: 0.9150\n",
      "Epoch 38/100\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 0.2761 - accuracy: 0.9189 - val_loss: 0.3206 - val_accuracy: 0.9108\n",
      "Epoch 39/100\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.3388 - accuracy: 0.8990 - val_loss: 0.3203 - val_accuracy: 0.9037\n",
      "Epoch 40/100\n",
      "175/175 [==============================] - 7s 37ms/step - loss: 0.3021 - accuracy: 0.9097 - val_loss: 0.3023 - val_accuracy: 0.9162\n",
      "Epoch 40: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=100,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30231717228889465, 0.9162479043006897]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30\n",
      "accuracy: 91.62%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow GRU Model (with only one GRU layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(2, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/175 [==============================] - 6s 23ms/step - loss: 1.1526 - accuracy: 0.5696 - val_loss: 1.0540 - val_accuracy: 0.6055\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 1.0402 - accuracy: 0.6037 - val_loss: 1.0532 - val_accuracy: 0.5733\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 1.0264 - accuracy: 0.5992 - val_loss: 1.0293 - val_accuracy: 0.6244\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 1.0167 - accuracy: 0.5948 - val_loss: 1.0248 - val_accuracy: 0.6047\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 1.0120 - accuracy: 0.5973 - val_loss: 1.0135 - val_accuracy: 0.6076\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 1.0065 - accuracy: 0.6023 - val_loss: 1.0094 - val_accuracy: 0.5817\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 1.0013 - accuracy: 0.5973 - val_loss: 1.0033 - val_accuracy: 0.5829\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9981 - accuracy: 0.6036 - val_loss: 1.0119 - val_accuracy: 0.5854\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.9972 - accuracy: 0.5989 - val_loss: 1.0062 - val_accuracy: 0.5833\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9926 - accuracy: 0.6071 - val_loss: 1.0012 - val_accuracy: 0.5854\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.9915 - accuracy: 0.6080 - val_loss: 0.9962 - val_accuracy: 0.5854\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.9885 - accuracy: 0.6088 - val_loss: 0.9935 - val_accuracy: 0.6327\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9875 - accuracy: 0.6080 - val_loss: 0.9914 - val_accuracy: 0.6319\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9853 - accuracy: 0.6127 - val_loss: 0.9958 - val_accuracy: 0.5976\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.9842 - accuracy: 0.6163 - val_loss: 0.9909 - val_accuracy: 0.6156\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.9817 - accuracy: 0.6158 - val_loss: 0.9861 - val_accuracy: 0.6206\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.9807 - accuracy: 0.6176 - val_loss: 0.9856 - val_accuracy: 0.6152\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.9777 - accuracy: 0.6217 - val_loss: 0.9902 - val_accuracy: 0.5863\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.9745 - accuracy: 0.6213 - val_loss: 0.9756 - val_accuracy: 0.6378\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9726 - accuracy: 0.6224 - val_loss: 0.9747 - val_accuracy: 0.6436\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.9694 - accuracy: 0.6217 - val_loss: 0.9659 - val_accuracy: 0.6231\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9589 - accuracy: 0.6233 - val_loss: 0.9767 - val_accuracy: 0.6043\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.9475 - accuracy: 0.6348 - val_loss: 1.0238 - val_accuracy: 0.5854\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9387 - accuracy: 0.6400 - val_loss: 0.9302 - val_accuracy: 0.6600\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.9234 - accuracy: 0.6531 - val_loss: 0.9053 - val_accuracy: 0.6709\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.9113 - accuracy: 0.6588 - val_loss: 1.1263 - val_accuracy: 0.5854\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9007 - accuracy: 0.6649 - val_loss: 0.8894 - val_accuracy: 0.6704\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.8909 - accuracy: 0.6664 - val_loss: 0.8906 - val_accuracy: 0.6600\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.8855 - accuracy: 0.6633 - val_loss: 0.9818 - val_accuracy: 0.6068\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.8826 - accuracy: 0.6669 - val_loss: 0.8834 - val_accuracy: 0.6692\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.8826 - accuracy: 0.6678 - val_loss: 0.8670 - val_accuracy: 0.6813\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.8746 - accuracy: 0.6631 - val_loss: 0.8623 - val_accuracy: 0.6792\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.8759 - accuracy: 0.6648 - val_loss: 0.9104 - val_accuracy: 0.6487\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8729 - accuracy: 0.6617 - val_loss: 0.8906 - val_accuracy: 0.6746\n",
      "Epoch 35/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.8631 - accuracy: 0.6689 - val_loss: 0.8710 - val_accuracy: 0.6776\n",
      "Epoch 36/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.8642 - accuracy: 0.6671 - val_loss: 0.8583 - val_accuracy: 0.6746\n",
      "Epoch 37/100\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.8625 - accuracy: 0.6696 - val_loss: 0.9078 - val_accuracy: 0.6725\n",
      "Epoch 38/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8548 - accuracy: 0.6700 - val_loss: 0.8502 - val_accuracy: 0.6704\n",
      "Epoch 39/100\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.8566 - accuracy: 0.6653 - val_loss: 1.1070 - val_accuracy: 0.5879\n",
      "Epoch 40/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.8510 - accuracy: 0.6673 - val_loss: 0.8677 - val_accuracy: 0.6587\n",
      "Epoch 41/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8546 - accuracy: 0.6701 - val_loss: 0.8260 - val_accuracy: 0.6750\n",
      "Epoch 42/100\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.8631 - accuracy: 0.6640 - val_loss: 0.8396 - val_accuracy: 0.6822\n",
      "Epoch 43/100\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.8367 - accuracy: 0.6773 - val_loss: 0.8172 - val_accuracy: 0.6817\n",
      "Epoch 44/100\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.8328 - accuracy: 0.6786 - val_loss: 1.0443 - val_accuracy: 0.6235\n",
      "Epoch 45/100\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.8344 - accuracy: 0.6802 - val_loss: 0.8259 - val_accuracy: 0.6985\n",
      "Epoch 46/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.8362 - accuracy: 0.6807 - val_loss: 0.8209 - val_accuracy: 0.6918\n",
      "Epoch 47/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8330 - accuracy: 0.6818 - val_loss: 0.8115 - val_accuracy: 0.6893\n",
      "Epoch 48/100\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.8266 - accuracy: 0.6831 - val_loss: 0.8513 - val_accuracy: 0.6654\n",
      "Epoch 49/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.8255 - accuracy: 0.6872 - val_loss: 0.8135 - val_accuracy: 0.6930\n",
      "Epoch 50/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8230 - accuracy: 0.6865 - val_loss: 0.8247 - val_accuracy: 0.6943\n",
      "Epoch 51/100\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.8155 - accuracy: 0.6895 - val_loss: 0.8152 - val_accuracy: 0.7052\n",
      "Epoch 52/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.8141 - accuracy: 0.6913 - val_loss: 0.7976 - val_accuracy: 0.7106\n",
      "Epoch 53/100\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.8112 - accuracy: 0.6951 - val_loss: 0.8222 - val_accuracy: 0.7098\n",
      "Epoch 54/100\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.8130 - accuracy: 0.6967 - val_loss: 0.8051 - val_accuracy: 0.7014\n",
      "Epoch 55/100\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.8143 - accuracy: 0.6947 - val_loss: 0.8853 - val_accuracy: 0.6788\n",
      "Epoch 56/100\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.8104 - accuracy: 0.6890 - val_loss: 0.7908 - val_accuracy: 0.7035\n",
      "Epoch 57/100\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.8062 - accuracy: 0.6965 - val_loss: 0.7983 - val_accuracy: 0.7044\n",
      "Epoch 58/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8050 - accuracy: 0.6933 - val_loss: 0.8243 - val_accuracy: 0.6943\n",
      "Epoch 59/100\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.8027 - accuracy: 0.6960 - val_loss: 0.8466 - val_accuracy: 0.6926\n",
      "Epoch 60/100\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.8011 - accuracy: 0.6999 - val_loss: 0.7987 - val_accuracy: 0.7056\n",
      "Epoch 61/100\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.7981 - accuracy: 0.6997 - val_loss: 0.7818 - val_accuracy: 0.7186\n",
      "Epoch 62/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.7958 - accuracy: 0.6967 - val_loss: 0.8222 - val_accuracy: 0.6922\n",
      "Epoch 63/100\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.7921 - accuracy: 0.7010 - val_loss: 0.9103 - val_accuracy: 0.6792\n",
      "Epoch 64/100\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.8012 - accuracy: 0.6949 - val_loss: 0.8053 - val_accuracy: 0.6993\n",
      "Epoch 65/100\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.7868 - accuracy: 0.7012 - val_loss: 0.8537 - val_accuracy: 0.6780\n",
      "Epoch 66/100\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.7892 - accuracy: 0.7008 - val_loss: 0.8060 - val_accuracy: 0.6943\n",
      "Epoch 66: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=100,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8059611320495605, 0.694304883480072]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.81\n",
      "accuracy: 69.43%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep GRU Model (with only two GRU layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(7, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(7, return_sequences=False),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/175 [==============================] - 9s 39ms/step - loss: 1.1332 - accuracy: 0.5800 - val_loss: 1.0554 - val_accuracy: 0.6055\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 8s 45ms/step - loss: 1.0208 - accuracy: 0.5944 - val_loss: 1.0580 - val_accuracy: 0.5854\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.9802 - accuracy: 0.6184 - val_loss: 0.8627 - val_accuracy: 0.6859\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 7s 43ms/step - loss: 0.7284 - accuracy: 0.7421 - val_loss: 0.6693 - val_accuracy: 0.7885\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 0.6034 - accuracy: 0.8098 - val_loss: 0.5413 - val_accuracy: 0.8405\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 7s 39ms/step - loss: 0.5533 - accuracy: 0.8293 - val_loss: 0.6117 - val_accuracy: 0.8040\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.5953 - accuracy: 0.8047 - val_loss: 0.7267 - val_accuracy: 0.7479\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 7s 39ms/step - loss: 0.5211 - accuracy: 0.8410 - val_loss: 0.5847 - val_accuracy: 0.8262\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.4965 - accuracy: 0.8501 - val_loss: 0.4740 - val_accuracy: 0.8614\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.4894 - accuracy: 0.8518 - val_loss: 0.4911 - val_accuracy: 0.8442\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 8s 47ms/step - loss: 0.4678 - accuracy: 0.8579 - val_loss: 0.4542 - val_accuracy: 0.8606\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.4645 - accuracy: 0.8589 - val_loss: 0.4561 - val_accuracy: 0.8576\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.4616 - accuracy: 0.8528 - val_loss: 0.4704 - val_accuracy: 0.8547\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 7s 43ms/step - loss: 0.4562 - accuracy: 0.8595 - val_loss: 0.4924 - val_accuracy: 0.8375\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.4430 - accuracy: 0.8597 - val_loss: 0.4094 - val_accuracy: 0.8723\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.4289 - accuracy: 0.8645 - val_loss: 0.4054 - val_accuracy: 0.8744\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.4193 - accuracy: 0.8688 - val_loss: 0.4005 - val_accuracy: 0.8735\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.4141 - accuracy: 0.8681 - val_loss: 0.4074 - val_accuracy: 0.8668\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.4013 - accuracy: 0.8719 - val_loss: 0.3977 - val_accuracy: 0.8652\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.4219 - accuracy: 0.8623 - val_loss: 0.3831 - val_accuracy: 0.8786\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 0.3808 - accuracy: 0.8780 - val_loss: 0.4660 - val_accuracy: 0.8421\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 8s 47ms/step - loss: 0.3667 - accuracy: 0.8844 - val_loss: 0.4829 - val_accuracy: 0.8656\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 8s 47ms/step - loss: 0.3637 - accuracy: 0.8925 - val_loss: 0.3637 - val_accuracy: 0.8966\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.3839 - accuracy: 0.8869 - val_loss: 0.3734 - val_accuracy: 0.8932\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.3453 - accuracy: 0.9061 - val_loss: 0.3510 - val_accuracy: 0.9003\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 0.3369 - accuracy: 0.9033 - val_loss: 0.3501 - val_accuracy: 0.9041\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.3389 - accuracy: 0.8995 - val_loss: 0.3334 - val_accuracy: 0.9083\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 0.3362 - accuracy: 0.9061 - val_loss: 0.3733 - val_accuracy: 0.8936\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 10s 58ms/step - loss: 0.3369 - accuracy: 0.9031 - val_loss: 0.3205 - val_accuracy: 0.9125\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 0.3312 - accuracy: 0.9067 - val_loss: 0.3492 - val_accuracy: 0.9012\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 0.3478 - accuracy: 0.9020 - val_loss: 0.3550 - val_accuracy: 0.8953\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 11s 60ms/step - loss: 0.3228 - accuracy: 0.9112 - val_loss: 0.3228 - val_accuracy: 0.9008\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 0.3220 - accuracy: 0.9065 - val_loss: 0.3725 - val_accuracy: 0.8882\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 0.3132 - accuracy: 0.9079 - val_loss: 0.3245 - val_accuracy: 0.9075\n",
      "Epoch 34: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=100,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32454797625541687, 0.9074539542198181]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.32\n",
      "accuracy: 90.75%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test values of each model you built "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                 Model\t                          Validation Accuracy\n",
    "    cross-sectional shallow model (1 hidden layer)\t       92.92%\n",
    "\n",
    "    cross-sectional deep model (3 hidden layers)\t         93.68%\n",
    "\n",
    "    sequential shallow LSTM model (1 LSTM layer)\t         77.64%\n",
    "\n",
    "    sequential deep LSTM model (2 LSTM layers)\t           91.62%\n",
    "\n",
    "    sequential shallow GRU model (1 GRU layer)\t           69.43%\n",
    "\n",
    "    sequential deep GRU model (2 GRU layers)\t             90.75%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? \n",
    "\n",
    "The cross-sectional deep model with 3 hidden layers (PIPE Architecture) performs the best. It has the highest validation accuracy (93.68%) among all the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it compare to baseline? \n",
    "\n",
    "The majority class (0) is about 58.20% of the data. Anything above this should be a good model for us. The best model is 35.48% above the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
